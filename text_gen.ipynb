{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/space.txt', 'r')\n",
    "data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "* Remove punctuations and numbers\n",
    "* Remove single characters\n",
    "* Replace multiple spaces with a sinlge space\n",
    "* Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(s):\n",
    "    sentence = re.sub(r'[^a-zA-Z]', ' ', s)\n",
    "    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence.lower()\n",
    "\n",
    "text = preprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize words\n",
    "* Tokenize the text into individual words\n",
    "* Remove stopwords (optional): application specific\n",
    "* Convert the tokenized words to numbers (indices)\n",
    "* Create word-to-index dictionary\n",
    "* Create index-to-word dictionary (by reversing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 1889\n",
      "Unique words: 754\n",
      "Vocabulary size: 755\n",
      "Word to Index dictionary created\n",
      "Index to Word dictionary created\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "words = word_tokenize(text)\n",
    "words = [w for w in words if w not in stopwords.words('english')]\n",
    "\n",
    "num_words = len(words)\n",
    "print('Total words:', num_words)\n",
    "\n",
    "unique_words = len(set(words))\n",
    "print('Unique words:', unique_words)\n",
    "\n",
    "tokenizer = Tokenizer(num_words = unique_words + 1)\n",
    "tokenizer.fit_on_texts(words)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary size:', vocab_size)\n",
    "\n",
    "word_to_index = tokenizer.word_index\n",
    "print('Word to Index dictionary created')\n",
    "\n",
    "index_to_word = dict(map(reversed, word_to_index.items()))\n",
    "print('Index to Word dictionary created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many-to-one Sequence problem: LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape input and output, and Normalize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1789, 100, 1)\n",
      "y shape: (1789, 755)\n"
     ]
    }
   ],
   "source": [
    "from numpy import reshape\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "input_sequence = []\n",
    "input_sequence_len = 100\n",
    "output_words = []\n",
    "\n",
    "for i in range(0, num_words - input_sequence_len, 1):\n",
    "    in_seq = words[i:i + input_sequence_len]\n",
    "    out_seq = words[i + input_sequence_len]\n",
    "    input_sequence.append([word_to_index[word] for word in in_seq])\n",
    "    output_words.append(word_to_index[out_seq])\n",
    "    \n",
    "X = reshape(input_sequence, (len(input_sequence), input_sequence_len, 1))\n",
    "X_trn = X / float(vocab_size)\n",
    "\n",
    "y_trn = to_categorical(output_words)\n",
    "\n",
    "print(\"X shape:\", X_trn.shape)\n",
    "print(\"y shape:\", y_trn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Stacked LSTM Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100, 200)          161600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 100)          120400    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 50)           30200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 25)                7600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 755)               19630     \n",
      "=================================================================\n",
      "Total params: 339,430\n",
      "Trainable params: 339,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(X_trn.shape[1], X_trn.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(25))\n",
    "model.add(Dense(y_trn.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1789/1789 [==============================] - 14s 8ms/step - loss: 6.5922\n",
      "Epoch 2/10\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 6.3983\n",
      "Epoch 3/10\n",
      "1789/1789 [==============================] - 14s 8ms/step - loss: 6.2151\n",
      "Epoch 4/10\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 6.1400\n",
      "Epoch 5/10\n",
      "1789/1789 [==============================] - 14s 8ms/step - loss: 6.1123\n",
      "Epoch 6/10\n",
      "1789/1789 [==============================] - 14s 8ms/step - loss: 6.1033\n",
      "Epoch 7/10\n",
      "1789/1789 [==============================] - 13s 7ms/step - loss: 6.0963\n",
      "Epoch 8/10\n",
      "1789/1789 [==============================] - 12s 7ms/step - loss: 6.0943\n",
      "Epoch 9/10\n",
      "1789/1789 [==============================] - 12s 7ms/step - loss: 6.0929\n",
      "Epoch 10/10\n",
      "1789/1789 [==============================] - 12s 7ms/step - loss: 6.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x13a359f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_trn, y_trn, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction\n",
    "* Randomly select a sequence\n",
    "* Obtain the words from index-to-word dictionary\n",
    "* Predict a one-hot encoded array of indices\n",
    "  * the index that contains 1 will be the index value of the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutron stars black holes gravitational pull high even light escape constellations group stars forming various shapes called constellation star patterns laghu saptarshi ursa minor one constellation vrihat saptarshi also known ursa major group seven stars another constellation forms part constellation big bear seen summer time early part night orion mriga another well known constellation seen winter late evenings star sirius brightest star sky located close orion cassiopeia another prominent constellation northern sky visible winter early part night constellation stars large number stars however see bright stars constellation naked eye stars make constellation distance line sight sky galaxies galaxy system stars\n"
     ]
    }
   ],
   "source": [
    "from numpy import random, argmax\n",
    "\n",
    "random_seq_index = random.randint(0, len(input_sequence)-1)\n",
    "random_seq = input_sequence[random_seq_index]\n",
    "\n",
    "word_seq = [index_to_word[val] for val in random_seq]\n",
    "print(' '.join(word_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " neutron stars black holes gravitational pull high even light escape constellations group stars forming various shapes called constellation star patterns laghu saptarshi ursa minor one constellation vrihat saptarshi also known ursa major group seven stars another constellation forms part constellation big bear seen summer time early part night orion mriga another well known constellation seen winter late evenings star sirius brightest star sky located close orion cassiopeia another prominent constellation northern sky visible winter early part night constellation stars large number stars however see bright stars constellation naked eye stars make constellation distance line sight sky galaxies galaxy system stars earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth earth\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    int_sample = reshape(random_seq, (1, len(random_seq), 1))\n",
    "    int_sample = int_sample / float(vocab_size)\n",
    "\n",
    "    predicted_word_index = model.predict(int_sample, verbose=0)\n",
    "    predicted_word_id = argmax(predicted_word_index)\n",
    "    \n",
    "    seq_in = [index_to_word[index] for index in random_seq]\n",
    "\n",
    "    word_seq.append(index_to_word[predicted_word_id])\n",
    "\n",
    "    random_seq.append(predicted_word_id)\n",
    "    \n",
    "    random_seq = random_seq[1:len(random_seq)]\n",
    "\n",
    "output = \"\"\n",
    "for word in word_seq:\n",
    "    output = output + \" \" + word\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('model.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
